{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymanmostafa11/Andromeda/blob/main/NasaSpaceApps'22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Can AI preserve our science legacy"
      ],
      "metadata": {
        "id": "oZjsb91nDK_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize , sent_tokenize\n",
        "from nltk import pos_tag\n",
        "import string \n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string , preprocess_documents\n",
        "from gensim.utils import lemmatize"
      ],
      "metadata": {
        "id": "yOdJBevFIfMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "REdY5Mb1Xfyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_root = 'https://ntrs.nasa.gov'"
      ],
      "metadata": {
        "id": "kLC1oh1hY26F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getDocsLinks(count=100):\n",
        "  offset = 0\n",
        "  url = api_root + f'/api/citations/search?center=CDMS&page.size=100&offset={offset}'\n",
        "\n",
        "  download_urls = []\n",
        "  while len(download_urls) < count:\n",
        "    resp = requests.get(url).json()\n",
        "    #print(resp['results'][-1]['downloads'][0]['links']['fulltext'])\n",
        "    downloadable_files = [ ( i['id'] ,i['downloads'][0]['links']['fulltext'] )\n",
        "                          for i in resp['results'] \n",
        "                          if len(i['downloads']) > 0]\n",
        "    download_urls.extend(downloadable_files)\n",
        "    offset += 100\n",
        "\n",
        "  return download_urls[:count]\n"
      ],
      "metadata": {
        "id": "J-KD44qkDSGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = getDocsLinks(100)"
      ],
      "metadata": {
        "id": "-QItd-qOE5FM"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4zsdG5xMzlD",
        "outputId": "1b50f2d1-c12c-4207-8bbb-f4254218b39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [ (i[0], requests.get(api_root + i[1]).content) for i in docs ]"
      ],
      "metadata": {
        "id": "KmKrVlybKZPp"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import glob\n",
        "\n",
        "from gensim import utils\n",
        "from gensim.parsing.porter import PorterStemmer\n",
        "\n",
        "\n",
        "# improved list from Stone, Denis, Kwantes (2010)\n",
        "STOPWORDS = \"\"\"\n",
        "a about above across after afterwards again against all almost alone along already also although always am among amongst amoungst amount an and another any anyhow anyone anything anyway anywhere are around as at back be\n",
        "became because become becomes becoming been before beforehand behind being below beside besides between beyond bill both bottom but by call can\n",
        "cannot cant co computer con could couldnt cry de describe\n",
        "detail did didn do does doesn doing don done down due during\n",
        "each eg eight either eleven else elsewhere empty enough etc even ever every everyone everything everywhere except few fifteen\n",
        "fify fill find fire first five for former formerly forty found four from front full further get give go\n",
        "had has hasnt have he hence her here hereafter hereby herein hereupon hers herself him himself his how however hundred i ie\n",
        "if in inc indeed interest into is it its itself keep last latter latterly least less ltd\n",
        "just\n",
        "kg km\n",
        "made make many may me meanwhile might mill mine more moreover most mostly move much must my myself name namely\n",
        "neither never nevertheless next nine no nobody none noone nor not nothing now nowhere of off\n",
        "often on once one only onto or other others otherwise our ours ourselves out over own part per\n",
        "perhaps please put rather re\n",
        "quite\n",
        "rather really regarding\n",
        "same say see seem seemed seeming seems serious several she should show side since sincere six sixty so some somehow someone something sometime sometimes somewhere still such system take ten\n",
        "than that the their them themselves then thence there thereafter thereby therefore therein thereupon these they thick thin third this those though three through throughout thru thus to together too top toward towards twelve twenty two un under\n",
        "until up unless upon us used using\n",
        "various very very via\n",
        "was we well were what whatever when whence whenever where whereafter whereas whereby wherein whereupon wherever whether which while whither who whoever whole whom whose why will with within without would yet you\n",
        "your yours yourself yourselves\n",
        "\"\"\"\n",
        "STOPWORDS = frozenset(w for w in STOPWORDS.split() if w)\n",
        "\n",
        "def remove_stopwords(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return \" \".join(w for w in s.split() if w not in STOPWORDS)\n",
        "RE_PUNCT = re.compile('([%s])+' % re.escape(string.punctuation), re.UNICODE)\n",
        "def strip_punctuation(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return RE_PUNCT.sub(\" \", s)\n",
        "\n",
        "strip_punctuation2 = strip_punctuation\n",
        "\n",
        "RE_TAGS = re.compile(r\"<([^>]+)>\", re.UNICODE)\n",
        "def strip_tags(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return RE_TAGS.sub(\"\",s)\n",
        "\n",
        "\n",
        "\n",
        "def strip_short(s, minsize=3):\n",
        "    s = utils.to_unicode(s)\n",
        "    return \" \".join(e for e in s.split() if len(e) >= minsize)\n",
        "\n",
        "\n",
        "\n",
        "RE_NUMERIC = re.compile(r\"[0-9]+\", re.UNICODE)\n",
        "def strip_numeric(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return RE_NUMERIC.sub(\"\", s)\n",
        "\n",
        "\n",
        "\n",
        "RE_NONALPHA = re.compile(r\"\\W\", re.UNICODE)\n",
        "def strip_non_alphanum(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return RE_NONALPHA.sub(\" \", s)\n",
        "\n",
        "\n",
        "\n",
        "RE_WHITESPACE = re.compile(r\"(\\s)+\", re.UNICODE)\n",
        "def strip_multiple_whitespaces(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return RE_WHITESPACE.sub(\" \", s)\n",
        "\n",
        "RE_AL_NUM = re.compile(r\"([a-z]+)([0-9]+)\", flags=re.UNICODE)\n",
        "RE_NUM_AL = re.compile(r\"([0-9]+)([a-z]+)\", flags=re.UNICODE)\n",
        "def split_alphanum(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    s = RE_AL_NUM.sub(r\"\\1 \\2\", s)\n",
        "    return RE_NUM_AL.sub(r\"\\1 \\2\", s)\n",
        "\n",
        "\n",
        "\n",
        "def stem_text(text):\n",
        "    \"\"\"\n",
        "    Return lowercase and (porter-)stemmed version of string `text`.\n",
        "    \"\"\"\n",
        "    text = utils.to_unicode(text)\n",
        "    p = PorterStemmer()\n",
        "    return ' '.join(p.stem(word) for word in text.split())\n",
        "\n",
        "stem = stem_text\n",
        "\n",
        "DEFAULT_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation, strip_multiple_whitespaces,\n",
        "                   strip_numeric, remove_stopwords, strip_short]\n",
        "\n",
        "\n",
        "def preprocess_string(s, filters=DEFAULT_FILTERS):\n",
        "    s = utils.to_unicode(s)\n",
        "    for f in filters:\n",
        "        s = f(s)\n",
        "    return s.split()\n"
      ],
      "metadata": {
        "id": "Dl_Sxu3g3jCq"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataSet = list()\n",
        "for i in range(0,99):\n",
        "  text = str(texts[i][1])\n",
        "  dataSet.append(preprocess_string(text.replace('\\\\n', ' ').replace('-',' ')))"
      ],
      "metadata": {
        "id": "eTxkrLSZ3kOH"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "dataSet[0] = [lemmatizer.lemmatize(word) for word in dataSet[0]]"
      ],
      "metadata": {
        "id": "yC_hNyGI9Owq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataSet[0]"
      ],
      "metadata": {
        "id": "ogmns0kq-Btr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import gensim.corpora \n",
        "dictionary = gensim.corpora.Dictionary(dataSet)"
      ],
      "metadata": {
        "id": "Yoxzpl93nTyH"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in dataSet]"
      ],
      "metadata": {
        "id": "PrPDaVmUpnWa"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
        "                                   num_topics = 5, \n",
        "                                   id2word = dictionary,                                    \n",
        "                                   )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exo75AR-wfxV",
        "outputId": "1b4bb7e1-f471-41b7-a957-7f8a2237a984"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model.print_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HLnat5Yw1wv",
        "outputId": "792792ea-5b1d-4c96-db58-55a6421cbc20"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.007*\"figur\" + 0.007*\"data\" + 0.005*\"temperatur\" + 0.004*\"time\" + 0.004*\"control\" + 0.004*\"test\" + 0.004*\"flight\" + 0.004*\"space\" + 0.003*\"level\" + 0.003*\"result\"'),\n",
              " (1,\n",
              "  '0.006*\"figur\" + 0.006*\"cloud\" + 0.005*\"test\" + 0.005*\"time\" + 0.005*\"control\" + 0.005*\"data\" + 0.004*\"nasa\" + 0.004*\"sec\" + 0.003*\"high\" + 0.003*\"oper\"'),\n",
              " (2,\n",
              "  '0.005*\"sec\" + 0.005*\"figur\" + 0.005*\"control\" + 0.004*\"pressur\" + 0.004*\"model\" + 0.004*\"data\" + 0.004*\"robot\" + 0.004*\"oper\" + 0.004*\"level\" + 0.003*\"test\"'),\n",
              " (3,\n",
              "  '0.008*\"figur\" + 0.008*\"data\" + 0.006*\"panel\" + 0.006*\"time\" + 0.005*\"temperatur\" + 0.004*\"model\" + 0.004*\"test\" + 0.004*\"cloud\" + 0.004*\"surfac\" + 0.004*\"pressur\"'),\n",
              " (4,\n",
              "  '0.006*\"data\" + 0.005*\"figur\" + 0.004*\"cloud\" + 0.004*\"model\" + 0.004*\"level\" + 0.004*\"solar\" + 0.003*\"process\" + 0.003*\"robot\" + 0.003*\"test\" + 0.003*\"base\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = [WordNetLemmatizer().lemmatize(i,'v')\n",
        "           for i in words \n",
        "           if len(i) > 3 and \n",
        "           i not in gensim.parsing.preprocessing.STOPWORDS]"
      ],
      "metadata": {
        "id": "pGIbxt3YKBUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FO1JLJdRfm-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "cF-u5VGLKoDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = gensim.corpora.Dictionary([results,])"
      ],
      "metadata": {
        "id": "PyQ5xZshLBoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow = dic.doc2bow(results)"
      ],
      "metadata": {
        "id": "zNSb40BbNye8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dic.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx05qT_TN4gm",
        "outputId": "6adc30ae-45df-4550-9e9f-26ef861c9a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ItemsView(<gensim.corpora.dictionary.Dictionary object at 0x7f6bf1334d50>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[[(dic[id], count) for id, count in line] for line in bow]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "E_KvaxfJQh1o",
        "outputId": "1a2d44f1-bcea-49e8-cf7d-8e91a0fd4b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-07182e8e51a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-07182e8e51a9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-07182e8e51a9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[ for i in bow]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "1Amkq7__R2fI",
        "outputId": "71cc612d-da47-4a73-a2c7-8658b64791af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-fbbebc37b999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-fbbebc37b999>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kMkD_I6PR524"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization"
      ],
      "metadata": {
        "id": "juFdHsgmo7du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = requests.get(api_root + '/api/citations/19810002806').json()"
      ],
      "metadata": {
        "id": "lZKuTEm4o7Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = str(requests.get(api_root + resp['downloads'][0]['links']['fulltext']).content)"
      ],
      "metadata": {
        "id": "7cGgwOB1pRWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.summarization import summarize"
      ],
      "metadata": {
        "id": "RGVaWQMrpTdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summarize(doc,0.01), sep='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASkI1sALqAvY",
        "outputId": "bd022573-6706-43f9-d46f-7fc96f0e23d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of Report and Period covered\\n\\nTRW Defense and Space Systems Group\\nPower Conversion Electronics Department\\nOne Space Park\\nRedondo Beach, California\\t 90278\\t\\n_\\n12, Sponsoring Ap ncy Nema and Address\\n\\nFinal TECH.\\nJune 1976- Jan. 1980\\n14, Sponsoring Apmcy code\\n\\nNASA Lewis Research Center\\n21000 Brookpark Road\\nC leveland, Ohio\\t 44135\\n\\n15, Supplementary Notes\\n\\nNASA Technical Monitor:\\t\\n\\n18,\\n\\n4\\n\\nJoseph Kolecki\\n\\nAbstract\\nThree basic switchin g regulators:\\t\\n\\nbuck, boost, and buck/boost, employing a Standardized\\n\\nControl Module (SCM) were characterized by a common small signal block diagram in Volume I of\\n\\nthe report, \"Application Handbook for a Standardized Control Module for DC-DC Converters,\"\\nEmploying the unified model, regulator performance such as stability, aud\\'iosusceptibility,\\n\\noutput impedance, and step-load transient were analyzed and key performance indices were\\nexpressed in simple analytical forms,\\t It has been demonstrated that the performance characteristics of all three regulators are shown to enjoy common properties due to the unique SCM_\\n\\ncontrol scheme.\\t This allows simple unified design procedure to be.realized in the present\\nreport (Volume II) for selecting the key SCM control parameters for an arbitrarily given power.stage configuration and parameter values, such that all regulator performance specifications\\n\\ncan be met and optimized concurrently in a sing le; design attempt.\\nIt is the author\\'; intent to make this report\\n\\n(Volume II)\\n\\nbe\\n\\nself -contained.\\t\\n\\nFor user\\'s\\n\\nconvenience, if he (or she)does not with to go through the detailed modeling and performance\\nanalyses as presented in\\n\\nVolume I,\\n\\nall key results and performance indices derived-in Volume I\\n\\nWhich are relevant to SCM design considerations are presented here in Volume II to facilitate\\nfrequent references,\\n\\n18, Distribution Statement\\n\\n17, Kay Words_iSuppested by Author(s)) _\\n\\n-DC-DC Converters\\t\\nPerformance Analysis\\nStandardized Control Module\\nUnclassified - Unlimited\\nAnalog Signal Processor\\nDigital Signal Processor\\nStability Analysis\\nDiscrete Time Domain Anal sis\\n21.\n",
            "xw?1ple- 3 DESIGN\\n\\n114\\t\\n\\nDETERMINATION OF 1%SIhE\\'RANCE FOR a\\'\\n\\n119\\n\\n6.3\\n6.4\\n\\n6.7\\n6.8\\n\\n);\\n\\n\\t\\n\\n{\\n\\n- gUCC.\\t\\nC\\n\\nPage\\n\\nNo!\\n\\n6.3(A) OPEN-LOOP CAIN, THEORY AND ` ME,ASURFMENT, OF THE\\nRUCK/UOOS1 CONVERTER IN Example\\n\\n4\\n\\nDESIGN\\t\\n\\n12\\n\\n6.9(0) OPEN-LOOP PHASE, IMEORY AND MEASUREMENT, OF THE\\nBUCK/BOOST CONVERTER IN Exempla 4 DESIGN\\t\\n\\n123\\n\\nAUDIO-SUSCEPTIBILITY CHARACTERISTIC, THEORY AND\\nExampxa 4 DESIGN \\t\\n\\n124\\n\\n6.10\\t\\n\\nMEASUREMENT, IN\\n\\n6.11\\t\\n\\nOUTPUT IMPEDANCE CRARACTERISTIC 0 TREORY AND\\n\\nRxampxa 4 DESIGN\\t\\nSTEP LOAD TRANSIENT RESPONSE IN Example 4 DESIGN\\t\\n\\nMEASUREMENT, IN\\n6.12\\t\\nE\\n\\nI\\n\\n125\\n126\\n\\n^\\nI\\n\\n1\\n\\nY\\n\\ni\\n\\nLIST Off` TABLES\\n\\nr\\n\\ni>\\t\\n\\nPACE\\nr\\t\\n\\nTABLE 3.1\\n\\nSUMMARY OF TRANSFER FUNCTIONS FOR ALL FUNCTIONAL\\nBLOCKS\\n\\nZS\\n\\nTABLE 3.2\\n\\nPULSE MODULATOR GAIN\\n\\n19\\n\\nTABLE 6.1\\n\\nSUMMARIES\\n\\nTABLE 6.2\\n\\nSUMMARIES OF THE BUCK/BOOST CONVERTER PERFORMANCES\\n(THEORY AND MEASUREMENT)\\n\\ni\\n\\nd\\n\\nOF BUCK REGULATOR PERFORMANCE CHARACTERISTICS\\n\\n104\\n\\n1 27\\n\\nI\\n\\ni\\n\\ni\\n\\n1\\n\\n(vii)\\'\\n\\nr\\n\\n\\t\\n\\nNOTATIONS\\nThe symbols for currents and voltaScs at 0e torq:inals of devices\\n\\nhave subscripts, The uppercase and lowercase zymbols and subscripts are\\nP\\n\\nused to distinguish between instantaneous values, quiescent values, and\\nsmall signal low-frequency averaged values.\\nvI\\t\\n\\nFor example;\\t\\n\\ninput voltagav instantaneous value\\n\\nr\\t\\n\\nv\\t\\n\\nI\\t\\n\\nV +v\\nI\\n\\n}\\nVI : input voltage, do average value\\ni\\nvi\\t\\n\\n`\\t\\n\\ni\\n\\n\\'\\t\\n\\ninput voltage, small signal low-frequency\\naverage term\\n\\nv0 s U\\' p ut voltage, instantaneous value\\nv0\\n\\nV\\n\\n+ v\\n\\nV\\' out)ut voltage, do average term\\nvo : output voltage, small-signal law-frequency\\naverage term.\\nTp : Period Oaf a switching cycle\\nTON : Switch on time\\nTFI: Switch off time in continuous inductor mmf operation\\n\\nTF2: A portion of the switching off time when the inductor mmf\\nhas vanished\\nd\\t\\nD\\t\\n\\nTON\\t\\n\\n_\\n\\nduty cycle ratio d z D+ a\\n\\nT\\n\\nSteady state duty cycle ratio\\nSmall signal, duty cycle variation\\n\\nd i\\t\\n\\nTOFF\\n\\ndt x D \\t\\n\\nd\\n\\nT\\n\\nD\\'\\t\\n\\nSteady state value for d\\'\\n-vii-\\n\\n9\\n\\nV\\n\\nC\\n\\n; Output filter capacitor voltage\\n\\nL ;\\n\\nInductor current of the buck, and boost converter\\n\\nMagnetie.\n",
            "The following performance improvements were observed\\n\\nand verified in rev ent: modeling and analysis efforts as discussed\\n\\n^\\'\\n\\na\\n\\nF\\n\\nt\\n\\n3\\n\\n1\\nk\\n\\nt\\n\\nCQ\\n\\ni\\n\\nt\\n^\\n\\nf\\n1\\n\\nt\\n\\n^\\n\\nt\\n\\nw\\xc2\\xb0\\n\\nUP\\n\\nwo\\t\\n\\n^\\n\\nto\\n\\na.\\n\\nZZ\\n\\n\\'U\\n\\nH; FVVJ\\n\\nT\\n\\nQ\\nIM\\n\\no\\n\\n9\\n\\nt\\n\\nIx\\n\\nN\\n\\nm\\n\\nLO)\\n\\nui\\nf\\n\\n{\\n\\nr-i\\n\\nD\\n\\nui -\\n\\n3\\n\\nzo\\nCL\\n\\nw\\n\\nw\\n\\nFp\\n\\nI_)\\n\\nH I ^.\\n\\nii\\n\\nin detail in Volume 1 of this report, Application Handbook for a\\nStandardized Control Module for DC-DC Converters.\\'\\n(1) High-gain, wide-bandwidth, and precision regulation\\n(2) Superior dynamic performances, such as taudiosusceptibility \\t\\n\\nE\\n\\nand transient response\\n(3) Stabilisation effect by shifting the positive zero oat the\\nright-half 9-plane to the left-half s- plana.\\n(4) A control :adaptive to the output filter parameter variations\\ndue to environmental rhangas, duty cycle modulations, and\\ncapacitive loading.\\nIn the present volume, the.\n",
            "Attention is now\\nbeing focused on development of analysis-based design guidelines for\\nselecting control parameters In, the ASP in order to achieve the\\nfollowing specified dynamic performances in one non-iterative design\\n\\nattempt:\\nA) frequency domain converter performance chara \\xe2\\x96\\xbacteristics\\n\\xe2\\x80\\xa2 Response of vA to a\\xe2\\x96\\xba sinusoidal, disturbance in v l (audio\\n\\nsusceptibility)\\n\\ni\\n\\nCHAPTER 111\\t\\n\\nj\\t\\n\\nANALYTICAL MODELS AND\\n\\n\\'a\\n\\nPt:1VORMANCC CHARACTERISTICS\\n\\nAs presented in, Volume 1 of this report, tine three basic SCR\\nswitching \\'^,regul.ators, buck, boost\\ncall\\n\\t\\n\\nand\\n\\nbuck/b oost ahown In Fig. la,\\n\\n\"\\'epresented by the common ftequeacy domain block diagram \\t\\n\\nshown i n Fig. 1.2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUN_tlEGqI-p",
        "outputId": "226ca103-b504-4813-bfa6-de19d6753900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 16.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38y3DMzo8YrO",
        "outputId": "4febfccd-d921-48e9-efce-e2c61a6177db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 12.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "G8QZ_AofqNc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "6FLtzmwX7yAd",
        "outputId": "5ce937fd-ee91-4ebd-f533-eff7cf5ce803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d37c78436823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't5-small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't5-small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T5Tokenizer.from_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3bJKDuQ8M8K",
        "outputId": "46bd6dbf-f86c-4ef8-c354-c921b52f9d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.utils.dummy_sentencepiece_objects.T5Tokenizer"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3v-DNy_E5E8L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}