{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Can AI preserve our science legacy"
      ],
      "metadata": {
        "id": "oZjsb91nDK_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import gensim.corpora \n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize , sent_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string \n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string , preprocess_documents\n",
        "from gensim.utils import lemmatize"
      ],
      "metadata": {
        "id": "yOdJBevFIfMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "REdY5Mb1Xfyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_root = 'https://ntrs.nasa.gov'"
      ],
      "metadata": {
        "id": "kLC1oh1hY26F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getDocsLinks(count = 100):\n",
        "  offset = 0\n",
        "  url = api_root + f'/api/citations/search?center=CDMS&page.size=100&offset={offset}'\n",
        "\n",
        "  download_urls = []\n",
        "  while len(download_urls) < count:\n",
        "     resp = requests.get(url).json()\n",
        "     #print(resp['results'][-1]['downloads'][0]['links']['fulltext'])\n",
        "     downloadable_files = [ ( i['id'] ,i['downloads'][0]['links']['fulltext'] )\n",
        "                          for i in resp['results'] \n",
        "                          if len(i['downloads']) > 0]\n",
        "     download_urls.extend(downloadable_files)\n",
        "     offset += 100\n",
        "     return download_urls[:count]\n"
      ],
      "metadata": {
        "id": "etBT8lEbY5AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getDocsLinkByID(id):\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "   download_url = None\n",
        "   download_url = requests.get(api_root + f'/api/citations/{id}/downloads/{id}.txt')\n",
        "\n",
        "\n",
        "   return download_url\n"
      ],
      "metadata": {
        "id": "J-KD44qkDSGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = getDocsLinks(count = 5)"
      ],
      "metadata": {
        "id": "-QItd-qOE5FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4zsdG5xMzlD",
        "outputId": "7479059e-7bd5-40d5-d712-3d3450e622bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [ (i[0], requests.get(api_root + i[1]).content, ) for i in docs ]"
      ],
      "metadata": {
        "id": "KmKrVlybKZPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import glob\n",
        "\n",
        "from gensim import utils\n",
        "from gensim.parsing.porter import PorterStemmer\n",
        "\n",
        "\n",
        "# improved list from Stone, Denis, Kwantes (2010)\n",
        "STOPWORDS = \"\"\"\n",
        "a about above across after afterwards again against all almost alone along already also although always am among amongst amoungst amount an and another any anyhow anyone anything anyway anywhere are around as at back be\n",
        "became because become becomes becoming been before beforehand behind being below beside besides between beyond bill both bottom but by call can\n",
        "cannot cant co computer con could couldnt cry de describe\n",
        "detail did didn do does doesn doing don done down due during\n",
        "each eg eight either eleven else elsewhere empty enough etc even ever every everyone everything everywhere except few fifteen\n",
        "fify fill find fire first five for former formerly forty found four from front full further get give go\n",
        "had has hasnt have he hence her here hereafter hereby herein hereupon hers herself him himself his how however hundred i ie\n",
        "if in inc indeed interest into is it its itself keep last latter latterly least less ltd\n",
        "just\n",
        "kg km\n",
        "made make many may me meanwhile might mill mine more moreover most mostly move much must my myself name namely\n",
        "neither never nevertheless next nine no nobody none noone nor not nothing now nowhere of off\n",
        "often on once one only onto or other others otherwise our ours ourselves out over own part per\n",
        "perhaps please put rather re\n",
        "quite\n",
        "rather really regarding\n",
        "same say see seem seemed seeming seems serious several she should show side since sincere six sixty so some somehow someone something sometime sometimes somewhere still such system take ten\n",
        "than that the their them themselves then thence there thereafter thereby therefore therein thereupon these they thick thin third this those though three through throughout thru thus to together too top toward towards twelve twenty two un under\n",
        "until up unless upon us used using\n",
        "various very very via\n",
        "was we well were what whatever when whence whenever where whereafter whereas whereby wherein whereupon wherever whether which while whither who whoever whole whom whose why will with within without would yet you\n",
        "your yours yourself yourselves\n",
        "\"\"\"\n",
        "STOPWORDS = frozenset(w for w in STOPWORDS.split() if w)\n",
        "\n",
        "def remove_stopwords(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return \" \".join(w for w in s.split() if w not in STOPWORDS)\n",
        "RE_PUNCT = re.compile('([%s])+' % re.escape(string.punctuation), re.UNICODE)\n",
        "def strip_punctuation(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return RE_PUNCT.sub(\" \", s)\n",
        "\n",
        "strip_punctuation2 = strip_punctuation\n",
        "\n",
        "RE_TAGS = re.compile(r\"<([^>]+)>\", re.UNICODE)\n",
        "def strip_tags(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return RE_TAGS.sub(\"\",s)\n",
        "\n",
        "\n",
        "\n",
        "def strip_short(s, minsize=3):\n",
        "    s = utils.to_unicode(s)\n",
        "    return \" \".join(e for e in s.split() if len(e) >= minsize)\n",
        "\n",
        "\n",
        "\n",
        "RE_NUMERIC = re.compile(r\"[0-9]+\", re.UNICODE)\n",
        "def strip_numeric(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return RE_NUMERIC.sub(\"\", s)\n",
        "\n",
        "\n",
        "\n",
        "RE_NONALPHA = re.compile(r\"\\W\", re.UNICODE)\n",
        "def strip_non_alphanum(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return RE_NONALPHA.sub(\" \", s)\n",
        "\n",
        "\n",
        "\n",
        "RE_WHITESPACE = re.compile(r\"(\\s)+\", re.UNICODE)\n",
        "def strip_multiple_whitespaces(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    return RE_WHITESPACE.sub(\" \", s)\n",
        "\n",
        "RE_AL_NUM = re.compile(r\"([a-z]+)([0-9]+)\", flags=re.UNICODE)\n",
        "RE_NUM_AL = re.compile(r\"([0-9]+)([a-z]+)\", flags=re.UNICODE)\n",
        "def split_alphanum(s):\n",
        "    s = utils.to_unicode(s)\n",
        "    s = RE_AL_NUM.sub(r\"\\1 \\2\", s)\n",
        "    return RE_NUM_AL.sub(r\"\\1 \\2\", s)\n",
        "\n",
        "\n",
        "\n",
        "def stem_text(text):\n",
        "    \"\"\"\n",
        "    Return lowercase and (porter-)stemmed version of string `text`.\n",
        "    \"\"\"\n",
        "    text = utils.to_unicode(text)\n",
        "    p = PorterStemmer()\n",
        "    return ' '.join(p.stem(word) for word in text.split())\n",
        "\n",
        "stem = stem_text\n",
        "\n",
        "DEFAULT_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation, strip_multiple_whitespaces,\n",
        "                   strip_numeric, remove_stopwords, strip_short]\n",
        "\n",
        "\n",
        "def preprocess_string(s, filters=DEFAULT_FILTERS):\n",
        "    s = utils.to_unicode(s)\n",
        "    for f in filters:\n",
        "        s = f(s)\n",
        "    return s.split()\n"
      ],
      "metadata": {
        "id": "Dl_Sxu3g3jCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataSet = list()\n",
        "for i in range(0,99):\n",
        "   text = str(texts[i][1])\n",
        "   dataSet.append(preprocess_string(text.replace('\\\\n', ' ').replace('-',' ')))"
      ],
      "metadata": {
        "id": "KYC5RBhHAToN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read(docNumber):\n",
        " docs = getDocsLinks(docNumber)\n",
        " texts = [ (i[0], requests.get(api_root + i[1]).content, ) for i in docs ]\n",
        "\n",
        " return texts"
      ],
      "metadata": {
        "id": "n2Se5LneBO_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(count):\n",
        " docs = getDocsLinks(count)\n",
        " #requests.get(api_root + 'api/citations/{id}/downloads/{id}.txt')\n",
        " texts = [ (i[0], requests.get(api_root + i[1]).content, ) for i in docs ]\n",
        " dataSet = list()\n",
        " for text in texts:\n",
        "   text = str(text[1])\n",
        "   dataSet.append(preprocess_string(text.replace('\\\\n', ' ').replace('-',' ')))\n",
        "\n",
        " lemmatizer = WordNetLemmatizer()\n",
        "\n",
        " for doc in dataSet:\n",
        "   doc = [lemmatizer.lemmatize(word) for word in doc]  \n",
        "\n",
        " \n",
        "\n",
        " return dataSet  "
      ],
      "metadata": {
        "id": "eTxkrLSZ3kOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testingPreprocessing(id):\n",
        "  doc = getDocsLinkByID(id)\n",
        "  doc = str(doc.content)\n",
        "  data = list()\n",
        "  data.append(preprocess_string(doc.replace('\\\\n', ' ').replace('-',' ')))\n",
        "\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  for doc in data:\n",
        "   doc = [lemmatizer.lemmatize(word) for word in doc]  \n",
        "  return data"
      ],
      "metadata": {
        "id": "E0cTE-lriNQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for doc in dataSet:\n",
        "  doc = [lemmatizer.lemmatize(word) for word in doc]"
      ],
      "metadata": {
        "id": "yC_hNyGI9Owq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doc2Bow(dataSet):\n",
        "  dictionary = gensim.corpora.Dictionary(dataSet)\n",
        "  bow_corpus = [dictionary.doc2bow(doc) for doc in dataSet]\n",
        "\n",
        "  return bow_corpus , dictionary"
      ],
      "metadata": {
        "id": "yneOt6sn9_YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.corpora \n",
        "dictionary = gensim.corpora.Dictionary(dataSet)"
      ],
      "metadata": {
        "id": "Yoxzpl93nTyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in dataSet]"
      ],
      "metadata": {
        "id": "PrPDaVmUpnWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataSet = preprocessing(100000)\n",
        "bow_corpus , dictionary = doc2Bow(dataSet)\n",
        "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
        "                                   num_topics = 5, \n",
        "                                   id2word = dictionary,                                    \n",
        "                                   )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exo75AR-wfxV",
        "outputId": "520b1dab-b328-4762-a2ce-cd3b4a916027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model.print_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HLnat5Yw1wv",
        "outputId": "398ae2dc-687c-47ae-e485-9aa321f46628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.008*\"sec\" + 0.006*\"data\" + 0.005*\"figure\" + 0.005*\"pressure\" + 0.004*\"temperature\" + 0.004*\"time\" + 0.004*\"control\" + 0.003*\"inlet\" + 0.003*\"test\" + 0.003*\"space\"'),\n",
              " (1,\n",
              "  '0.005*\"figure\" + 0.005*\"data\" + 0.003*\"flight\" + 0.003*\"nasa\" + 0.003*\"control\" + 0.003*\"temperature\" + 0.003*\"level\" + 0.003*\"time\" + 0.003*\"pressure\" + 0.003*\"robot\"'),\n",
              " (2,\n",
              "  '0.006*\"figure\" + 0.004*\"data\" + 0.004*\"sec\" + 0.003*\"model\" + 0.003*\"time\" + 0.003*\"control\" + 0.003*\"space\" + 0.003*\"based\" + 0.002*\"pressure\" + 0.002*\"nasa\"'),\n",
              " (3,\n",
              "  '0.007*\"data\" + 0.005*\"figure\" + 0.004*\"time\" + 0.004*\"nasa\" + 0.004*\"pressure\" + 0.003*\"cloud\" + 0.003*\"flow\" + 0.003*\"temperature\" + 0.003*\"test\" + 0.003*\"surface\"'),\n",
              " (4,\n",
              "  '0.008*\"data\" + 0.007*\"cloud\" + 0.006*\"figure\" + 0.004*\"temperature\" + 0.003*\"time\" + 0.003*\"control\" + 0.003*\"surface\" + 0.003*\"nasa\" + 0.002*\"flight\" + 0.002*\"results\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testData = testingPreprocessing(19900018794)\n",
        "test_bow_corpus , test_dictionary = doc2Bow(testData)\n",
        "\n",
        "for index  in sorted(lda_model[test_bow_corpus]):\n",
        "  print(lda_model.print_topic(index[0][0]))"
      ],
      "metadata": {
        "id": "8F7SR-r4ipU5",
        "outputId": "85f97c68-520b-42d4-8219-e86b9a6e6538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.006*\"figure\" + 0.004*\"data\" + 0.004*\"sec\" + 0.003*\"model\" + 0.003*\"time\" + 0.003*\"control\" + 0.003*\"space\" + 0.003*\"based\" + 0.002*\"pressure\" + 0.002*\"nasa\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "ZmzrHYI_Hmnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'finalized_keyWords_model.sav'\n",
        "pickle.dump(lda_model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "dSrpOPdpJVlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = pickle.load(open(filename, 'rb'))\n",
        "l.print_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ3dSSXlJkZf",
        "outputId": "444873d8-eb1f-46c8-bde9-6c521741bb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.008*\"sec\" + 0.006*\"data\" + 0.005*\"figure\" + 0.005*\"pressure\" + 0.004*\"temperature\" + 0.004*\"time\" + 0.004*\"control\" + 0.003*\"inlet\" + 0.003*\"test\" + 0.003*\"space\"'),\n",
              " (1,\n",
              "  '0.005*\"figure\" + 0.005*\"data\" + 0.003*\"flight\" + 0.003*\"nasa\" + 0.003*\"control\" + 0.003*\"temperature\" + 0.003*\"level\" + 0.003*\"time\" + 0.003*\"pressure\" + 0.003*\"robot\"'),\n",
              " (2,\n",
              "  '0.006*\"figure\" + 0.004*\"data\" + 0.004*\"sec\" + 0.003*\"model\" + 0.003*\"time\" + 0.003*\"control\" + 0.003*\"space\" + 0.003*\"based\" + 0.002*\"pressure\" + 0.002*\"nasa\"'),\n",
              " (3,\n",
              "  '0.007*\"data\" + 0.005*\"figure\" + 0.004*\"time\" + 0.004*\"nasa\" + 0.004*\"pressure\" + 0.003*\"cloud\" + 0.003*\"flow\" + 0.003*\"temperature\" + 0.003*\"test\" + 0.003*\"surface\"'),\n",
              " (4,\n",
              "  '0.008*\"data\" + 0.007*\"cloud\" + 0.006*\"figure\" + 0.004*\"temperature\" + 0.003*\"time\" + 0.003*\"control\" + 0.003*\"surface\" + 0.003*\"nasa\" + 0.002*\"flight\" + 0.002*\"results\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = [WordNetLemmatizer().lemmatize(i,'v')\n",
        "           for i in words \n",
        "           if len(i) > 3 and \n",
        "           i not in gensim.parsing.preprocessing.STOPWORDS]"
      ],
      "metadata": {
        "id": "pGIbxt3YKBUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FO1JLJdRfm-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "cF-u5VGLKoDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = gensim.corpora.Dictionary([results,])"
      ],
      "metadata": {
        "id": "PyQ5xZshLBoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow = dic.doc2bow(results)"
      ],
      "metadata": {
        "id": "zNSb40BbNye8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dic.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx05qT_TN4gm",
        "outputId": "6adc30ae-45df-4550-9e9f-26ef861c9a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ItemsView(<gensim.corpora.dictionary.Dictionary object at 0x7f6bf1334d50>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[[(dic[id], count) for id, count in line] for line in bow]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "E_KvaxfJQh1o",
        "outputId": "1a2d44f1-bcea-49e8-cf7d-8e91a0fd4b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-07182e8e51a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-07182e8e51a9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-07182e8e51a9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[ for i in bow]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "1Amkq7__R2fI",
        "outputId": "71cc612d-da47-4a73-a2c7-8658b64791af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-fbbebc37b999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-fbbebc37b999>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "qrgeWV6eN5xh",
        "outputId": "9ac94ca1-603e-43f2-d14c-6bd1bfb7f8d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rake_nltk\n",
        "from rake_nltk import Rake"
      ],
      "metadata": {
        "id": "JMRYBjD-NgqS",
        "outputId": "012424cd-8b05-4102-a5eb-15cdbd55922b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rake_nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.7/dist-packages (from rake_nltk) (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (7.1.2)\n",
            "Installing collected packages: rake-nltk\n",
            "Successfully installed rake-nltk-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[1][1].decode('utf-8')"
      ],
      "metadata": {
        "id": "gBkmxNNhTb-8",
        "outputId": "4a05866b-d2ec-47bf-ec0d-bf7992110815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I\\ni\\n\\n\\'\\n\\n.\\n\\nN A S A TN D-5515\\n- -\\n\\nNASA TECHNICAL NOTE\\n\\n4. /\\n\\nLOAN COPY: RETURN TO\\nAFWL ( W W - 2 )\\nKllRTLAND AFB, N MEX\\n\\nTHE EFFECT OF\\nOBJECT MOTION\\nI N FRAUNHOFERHOLOGRAPHY WITH\\nAPPLICATION TO VELOCITY\\nMEASUREMENTS\\n\\nby WiZZium P. Dotson, Jr.\\nMan fled Spacecraft Cejzter\\nHoustou, Texus\\n\\nN A T I O N AA E R O N A U T I C S N D P A C E D M I N I S T R A T I O N\\nL\\nA S\\nA\\n\\nW A S H I N G T O N , D. C.\\n\\nNOVEMBER 1969\\n1\\n\\nTECH LIBRARY KAFB, NM\\n\\n1\\nI\\nI\\n\\nI. R E P O R T NO.\\n\\n2.\\n\\nI\\n\\nNO.\\n\\n1\\n\\nNASA T N D-5515\\n4 . T I T L E AND\\n\\nG O V E R N M E N TA C C E S S I O N\\n\\nSUBTITLE\\n\\n3 RECIPIENT\\'SCATALOG\\n.\\n\\nI\\nT November 1969\\n5.\\n\\nTHE EFFECT OF OBJECT MOTION IN FRAUNHOFER\\nHOLOGRAPHY WITH APPLICATION TO VELOCITY\\nMEASUREMENTS\\n\\nREPORTDATE\\n\\n6.\\n\\n7 . AUTHOR(5)\\n\\nIO.\\n\\nt\\n\\nManned Spacecraft Center\\nHouston, Texas 77058\\n\\n11.\\n\\nC O N T R A C T OR G R A N T NO.\\n\\nR E P O R TT Y P EA N DP E R I O DC O V E R E D\\n\\nTechnical Note\\n\\nNational Aeronautics and Space Administration\\nWashington, D. C. 20546\\n\\ni\\n14.\\n\\n.\\n\\n\"\\n\\n..\\n\\n-~\\n.\\n\\nWORK U N I T NO.\\n\\n039-00-00-00-72\\n\\n13.\\n\\nS P O N S O R I N GA G E N C YN A M EA N DA D D R E S S\\n\\n\"\\n\\nNO.\\n\\ns-220\\n\\nP E R F O R M I N GO R G A N I Z A T I O NN A M EA N DA D D R E S S\\n\\n12.\\n\\nP E R F O R M I N GO R G A N I Z A T I O NC O D E\\n\\n8 . P E R F O R M I N GO R G A N I Z A T I O NR E P O R T\\n\\nWilliam P. Dotson, Jr., MSC\\n. .\\n9.\\n\\nNO.\\n\\nS P O N S O R I N GA G E N C YC O D E\\n\\n1\\n\\n15. S U P P L E M E N T A R YN O T E S\\n\\n.\"\\n16.\\n\\n~ ..\\n\\n~.\\n.\\n\\nABSTRACT\\n\\nThe in-line Fraunhofer hologram is analyzed with the assumption that the object moves a\\nsignificant distance during the observation time. An equation is derived which predicts the\\neffect that object motion has upon the recorded fringe pattern. An analysis of the fringe\\npattern recorded on the film consequently yields the total motion of the object during the\\nobservation time. It is also possible to reconstruct the resultant hologram so that the\\npath the object traveled during the exposure time\\nis reproduced. This knowledge, coupled\\nwith the exposure time, yields the desired measurement of the object velocity.\\n\\n-\\n\\n\"~\\n\"\\n\\n17.\\n\\nK E YW O R D S( S U P P L I E D\\n\\nB Y AUTHOR)\\n\\nLaser Velocimeter\\nMoving Object\\nHolography\\n. Fraunhofer Holography\\n* Holographic Velocimetry\\n\\'\\n\\n19.\\n\\nS E C U R I T YC L A S S I F I C A T I O N\\nh H l S REPORT)\\n\\n20. SECURITYCLASSIFICATION\\n(THIS\\n\\nUnclassified\\n.\\n\\nUnclassified\\n\\n- Unlimited\\n\\n21.\\n\\nNO.\\n\\nO FP A G E S\\n\\nUnclassified\\n\\n24\\n\\n--\\n\\n\\'For\\n\\n22.\\n\\nPRICE\\n\\nPAGE)\\n\\nsale by theClearinghousefor Federal Scientific and TechnicalInformation\\n22151\\nSpringfield,\\nVirginia\\n\\n$3.00\\n\\n*\\n\\nTHE EFFECT OF OBJECT MOTION IN FRAUNHOFER HOLOGRAPHY\\nWITH APPLICATION TO VELOCITY MEASUREMENTS\\n\\nBy W i l l i a m P. Dotson, Jr.*\\nManned Spacecraft Center\\nSUMMARY\\nThis study is concerned with the development of a theory to describe the effect\\nthat object velocity has upon the recorded fringe pattern in Fraunhofer holography.\\nThe conclusion is that, under the conditions described, objects may move\\na s much as\\n10 times their mean diameter during the observation time. This motion produces\\nfringes in the hologram which are descriptive of the motion.\\n\\nINTRODUCTION\\nA theoretical analysis is made of the time dependence of the intensity of the\\ntotal field at a recording 511-plane due to the interference of a constant-background\\nis then integrated over\\nfield with the field diffracted by a moving object. This equation\\nthe observation time in order to find the total energy distribution function in the\\n(1\\n1-plane.\\nThis study expands present Fraunhofer holography theory to include moving\\nobj e c t s , and the expanded theory is reduced to the usual result found in the literature\\nwhen the object is stationary. An experiment was designed to test the theory of this\\nstudy and was performed successfully.\\nThe\\nauthor\\nextends appreciation\\nhis\\nto\\nG. P. Bonner, N . K. Shankar,\\nand\\nC. W. Wells of the Science and Applications Directorate,NASA Manned Spacecraft Center, Houston, Texas, for their assistance in performing the laboratory experiments.\\n\\nSYMBOLS\\nA\\n\\naperture\\ndimensions\\n\\nI 1\\n\\nC = -ik 27rz\\n\\n*Captain, U . S. Air Force, assigned toNASA Manned Spacecraft Center.\\n\\nobject\\ntransmission\\nfunction\\n\\nD\\n\\nobject\\ndimension\\nd\\n\\nI\\n\\nintensity of an\\nelectromagnetic\\nfield\\n\\ni = f i\\n\\nJ\\n\\nenergy function\\ndensity\\n\\nK\\n\\namplitude of the\\nreference\\nelectromagnetic\\nfield\\n\\nL\\n\\nl e nt e r m ,\\ns\\n\\nR\\n\\nlength of theloci of pointsanobjectwillcoverduring\\n\\nr\\n\\ndistance from a point on theobjectto\\n\\nS\\n\\nX\\n\\na quadratic\\nphase\\nfactor\\n7\\n\\na pointinthe[q-plane\\n\\nx-coordinate of thedisplacement of thex\\'y\\'-planefromthexy-plane\\n\\nS\\n\\ny-coordinate of thedisplacement of thex\\'y\\'-planefromthexy-plane\\n\\nT\\n\\nt r a n s f o r m of the object field\\n\\nt\\n\\ntime\\n\\nV\\n\\ntransform of the object velocity\\n\\nV\\n\\nobject velocity\\n\\nx7 Y\\n\\ninput plane coordinates\\n\\nx\\' > Y\\'\\n\\ncoordinate system lying in the xy-plane but centered on the object\\n\\nZ\\n\\noptical axis\\n\\nY\\n\\nZ\\n\\n1\\n\\ndistance from the xy-plane to the <?-plane\\n\\nr\\n\\nlead, linear translation per revolution\\n\\nx\\n\\nwavelength of the coherent light source\\n\\n5,v\\n\\nrecording plane coordinates\\n\\n7\\n\\nobservation o r exposure time\\n\\nX\\n\\ninclination factor for a Huygens radiator\\n\\n2\\n\\n+\\n\\ntotal\\nelectromagnetic amplitude\\nfield\\np a r t of q due to the object field\\n\\n+O\\n\\n+r\\n\\np a r t of\\n\\n+\\n\\ndue to the reference field\\n\\nSuperscript:\\n\\n*\\n\\nconjugate\\n\\nTHE FRAUNHOFER DIFFRACTION THEORY FOR MOVING OBJECTS\\nReference is made in the following analysis to figure 1 in which three coordinate\\ns y s t e m s are indicated. The coordinate system centered on the object is used only once\\nto indicate a translation of the object center. Thereafter, only the input xy-plane and\\nthe recording ST-plane will be used.\\nAperture\\nboundary\\n\\nt\\n\\nPI ane\\nwave\\n\\nFigure 1. - Geometry for finding +(<, 77, t).\\n\\n3\\n\\nI1 I Ill I1 I1 IIllIlI~ll11111l1111\\n\\nBoundary Conditions\\nBy looking into the xy-plane from the right, an observer sees a hole (due to the\\nobject) in the field of constant amplitude and phase.\\nI an amplitude of K and a phase\\nf\\nof 0 O is a s s u m e d f o r the plane wave impinging on the xy-plane, the boundary conditions of the problem are\\n\\n*(x, Y )\\n\\n=\\n\\nI\\n\\nKD(x\\', y\\'), over the object cross section\\n(1)\\n= K, elsewhere in the aperture\\n\\nwhere D(x\\', y\\') represents the object transmission function.\\nSince the field is linear, superposition may be used. This enables the solution\\nof two relatively simple problems, as opposed to a single more complex problem.\\nTherefore, *(x, y ) is represented as the sum of the reference field and the object\\nfield, as follows.\\n*(x, y ) = $br(x, y)\\n\\n+ object\\nfield\\n\\n(2)\\n\\nwhere the reference field\\n\\nover the entire aperture.\\n\\nTo express the object field properly, the following definitions\\nthe object is centered at the origin of the xy-plane, then\\nobject\\nfield\\n\\nE.\\n\\nD\\n\\no\\n\\n(x, y)\\n\\nare required. If\\n\\n(4)\\n\\nIf the same object is centered at the origin of the x\\'y\\'-plane, which has a displacement\\nOf\\n\\n(sx\\'sy)\\n\\nfrom the xy-plane, then\\nobject\\nfield\\n\\n4\\n\\n$bo(x\\', y\\') = $b\\n\\nx-S\\n\\no(\\n\\nx\\n\\n, Y-S\\n\\nY)\\n\\nTherefore\\n\\nwhere\\n-K(1 - D), over the object cross section\\n(7)\\n= 0,\\n\\nUnder these conditions,\\na close approximation\\n\\nelsewhere in the aperture\\n\\nthe field in the ST-plane\\n\\n(ref. 1) due to\\n\\n*,(x, y) is, to\\n\\nprovided that\\n\\nA2\\nx>>\\nz\\n1\\n\\nFresnel I ntegral\\nUnder ordinary circumstances, a derivation of the diffracted field at the <q-plane\\ndue to the object field in the xy-plane is pointless because the problem has already\\nbeen solved. However, the treatment\\nof this problem is fundamental to later developments because the objective of this study is to find the field at the 577-plane with the\\nobject in motion; hence, the object will occupy many positions during the observation\\ntime. The symmetry of the usual problem has been removed by placing the object off\\nthe optical axis, as shown in figure 1.\\nThe physics of the problem are understood by considering the object field as a\\nsummation of a number of point sources and by applying the Huygens principle (ref. 2).\\nTherefore, the differential field at the [v-plane is\\n\\n5\\n\\nwhere\\n\\nx\\n\\nis an inclination factor for the Huygens radiator. The total field\\n\\nis then\\n\\nwhere the integral is a surface integral with limits set by the physical limits of the\\nobject geometry.\\nr must be found in terms\\n\\nTo evaluate the integral,\\n\\nBy the binomial series expansion,\\n\\nof the coordinates.\\n\\nif\\n\\nthen, to a close approximation\\n\\nor\\n\\nr = z\\n\\n1\\n\\n+5\\n\\n+ 7\\n2z 1\\n\\n+\\n\\nx2+y2_tx+17y\\n22 1\\nz1\\n\\nSubstituting equation (15) into equation (11)and realizing that amplitude variations in l/r will be small gives the Fresnel integral solution to the problem.\\n\\n-ik(x 2\\n\\n6\\n\\n+y\\n\\nFar-Field Conditions\\nEquation (16) is the integral for Fresnel diffraction. The equation for Fraunhofer\\ndiffraction is derivedfromequation(16)\\nby placing constraints on the term\\nexp[-ik(x2\\n\\n+ y2)/2zl]\\n\\nwhich appears inside the integral. If constraints are placed on\\n\\nthis term such that it remains constant (or nearly constant), the term may be taken out\\nof the integral. The magnitude\\nof t h i s t e r m is always unity, but its phase varies according to the limits of integration. These limits are set by the object geometry if the\\nobject is stationary. In the example considered by this study, the limits of integration\\nare s e t by the largest dimension of the loci of points occupied by the object during the\\nobservation time. The definition is then\\nR . 5 * largest dimension of the loci of points occupied\\nby the\\nobject time\\nduring\\nobservation\\nthe\\n\\nI the magnitude of R is such that the phase change\\nf\\n\\nof t h e t e r m exp[ik(x2\\n\\n(17)\\n\\n+ y2)/2,;]\\n\\nis equal to or less than 7r/2, the phase term should remain sufficently constant to\\nremoved from the integral. The requirement is\\n\\nkR2 7~\\n5 5 2\\n\\nor\\n\\nIn the usual case of stationary objects, the argument\\nobject dimension d, and the result\\nis\\n\\nEquation (20) is often reduced to (ref. 3)\\n\\nz1\\n\\nd2\\n>-r\\n\\nR is replaced by the\\n\\nbe\\n\\nsince experiment results indicate that equation (21) is adequate to assure the relative\\nconstancy of the phase term.\\nRecalling the definition of R, it is clear that equations (19) and (20) may be cornbined to yield\\n\\nExperiment results indicate that equation (22) may be reduced to\\n\\nEquations (22) and (23) then reduce to equations (20) and (21), respectively,\\nc a s e of stationary objects because, by definition, R becomes equal to d.\\n\\nfor the\\n\\nFraunhofer Integral\\nProvided equation (23) is satisfied, the Fresnel integral (eq. (16)) reduces to\\n\\nexp (-ikzl)exp\\n\\ns\\nwherexandyindicatetheaveragepositions\\nav\\nav\\nobservation time.\\n\\nof theobjectcenterduringthe\\n\\nIf it is imagined that the coordinate systems of figure 1 are s e t up so that x\\n\\nand ya,\\n\\nare both equal to zero, then\\n\\nav\\n\\nNote that the integral of equation (25) is a two-dimensional Fourier transform.\\nusing the Fourier translation theorem (ref. 4), if\\n\\nBy\\n\\nthen\\n\\nf(x-x\\')\\n\\n-\\n\\nF:e p-)\\n()x (,\\n\\nik[ x\\'\\n\\nBy applying equation (27) in two-dimensional form to equation (25)\\n\\nThe implication of equation (28) is that the object, for integration purposes, may\\nbe treated as if it were always centered at the origin of the xy-plane. Hence,\\nthe object transform is a function of the object geometry only. The displacement\\nof the\\nobject from the origin of the xy-plane is always performed by the modifying t e r m\\nwhich appears outside the integral. The separation\\nof this disexp ik [ s c qs\\n( x Y)/zil\\nplacement term from the surface integration over the object is an important result.\\nThis result will be used in the following section to generate a distribution function\\nproportional to the displacement of the object, a s a function of time, during the observation period.\\n\\nEnergy Distribution Function Over the Observation\\nTime in the m-Plane\\non sX and sY appearingin\\nequation (28). The total field in the (17-plane will be found at any instant of time by\\nare made.\\nsumming equations (8) and (28). For convenience, the following definitions\\n\\nIn thissection,timedependencewillbeplaced\\n\\n9\\n\\n1. The ratio\\n\\nx/zl may be evaluated from a Green\\'s function solution to the\\n\\nproblem depicted in figure\\n\\n1. The result is (ref. 1)\\n\\n2. Thelensterm\\n\\n3. The\\ntransform\\n\\nThe total field at the tq-plane at any instant of time is due to the summation of\\nthe reference field of equation (8) and the object field of equation (28).\\n\\nI)((, q , t) = K exp (-ikzl)\\n\\n+ exp(-ikzl)CLT\\nexp\\n\\n~~\\n\\n(32)\\n\\nz1\\nUpon removingthecommonphasetermexp-ikzandsetting\\n( 1)\\n\\n@ ( t , q t, ) = 1 + CLT exp\\n\\nK equalto 1\\n\\nZ\\n\\n1\\n\\n(33)\\n\\nThe instantaneous intensity at the tq-plane is\\n\\nI(t\\nwhere\\n\\n10\\n\\n*\\n\\nmeans\\nconjugate.\\n\\n9\\n\\n7 , t ) = I)((\\n\\n9\\n\\n17, t>I)*(t, 17, t )\\n\\n(34)\\n\\nForming the product indicated by equation (34)\\n\\nThe following should be noted concerning equation (35)\\n1. With zero displacement and no motion of the object, equation (35) reduces to\\nthe usual result found in the literature (refs. 1, 3, and 5 ) for the problem depicted in\\nfigure 1.\\n2. If an attempt is made to form a hologram, using the setup shown in figure 1\\na s an experiment base, the film does not record the intensity given by equation (35).\\nThe film actually records the total energy received; that is, the transmittance of the\\nhologram (ref. 6) is proportional to\\n\\nUpon performing the operation indicated by equation (36), the total energy distribution function in the 57-plane is\\n\\nI NTER PRETATI ON OF EQUATI ON (37)\\nEquation (37) consists of f o u r t e r m s . T h e first two t e r m s f o r m a background\\nfield which is essentially constant. On this background field, the third and fourth terms\\n\\n11\\n\\nimpress variations proportional to the object geometry and the displacement the obof\\nj e c t as a function of time. Attention may be restricted to the third term because the\\nfourth term is simply the conjugate of the third term. In the third term, ohly the last\\n\\'two factors, T and the integral, need to be considered because\\nC is a constant and\\nL is a lens term which controls the formation distance of the hologram of equation (37).\\n\\nDistribution Functions\\nThe two factors of interest appear in product form in the third term of equation (37). These two f a c t o r s a r e\\n\\nand\\n\\ndt\\n\\nfunctions.\\nBoth T and V are distribution\\n\\ns ( t )a r el i n e a r ,\\nboth T and\\nY\\nV are Fourier transforms. For illustrative purposes, the situation\\ninwhichboth\\nT\\nand V a r e F o u r i e r t r a n s f o r m s is considered.\\nThe Fourier transform variables\\n\\nIf sx(t)\\nand\\n\\nV ) are </zl and q/zl.\\n\\nin both cases (T and\\n\\nEquation (31) transforms a function of x and y, the object field in the xy-plane, to\\nfunction of [/zl and q/zl.\\n. Equation (38) transforms a function of time, the dis-\\n\\na function of\\n\\n5/\\n\\na\\n\\nand q/zl. Because\\n1\\nthese two functions (eqs. (31) and (38)) appear in product form in the [q-plane, either\\nequation may be forced (by proper control of s y s t e m p a r a m e t e r s i n a measurement\\nexperiment) to be dominant with respect to the other. The dominant equation will be\\nthe one which produces a distribution function with a smaller physical area of interest\\nthan the other equation produces.\\n\\nplacement of theobject in thexy-plane,to\\n\\nz\\n\\nDominant Function\\nTo understand how either distribution function (eq. (31) or (38)) may be forced to\\nbe dominant with respect to the other function, figure\\n2 must be considered. Figure\\n2\\n\\n12\\n\\n(a) Distribution of T.\\n\\nt\\n\\n(b) Distribution of V.\\n\\nFigure 2. - Distribution functions of T and V\\n\\nshows a c r o s s s e c t i o n f o r T when the object is a square with dimension d and a\\nc r o s s s e c t i o n for V when the displacement of the object, as a function of time, is\\ngiven by vt.\\n\\nsX (t) = vt\\n\\n(39)\\n\\ns (t) = 0\\nY\\n\\n13\\n\\nI.\\n\\nThe evaluation of equations (31) and (38) is as follows. I it is assumed that the obf\\nject is opaque, then by equation (7) with K = 1\\ny) = -1\\n\\nand\\n\\nwhich is of the form\\n\\nThe cross section in the 5-direction\\n\\nis plotted for T\\n\\nin figure 2.\\n\\nwhich is of the form\\n\\nThe cross section in the t-direction is plotted for V in figure 2. In figure 2, t h e c r o s s\\nsection is shown f o r v r >> d. In this situation, the object transform T, which multiplies the transform of the displacement function of the object V, a c t s as a constant of\\nunitywithrespectto\\nV. Hence, V is said to be dominant and, therefore,\\nis recorded\\nby the film in preference to T. On reconstruction of a hologram which was recorded\\nin the situation where v7 > d and which satisfies the condition of equation (23), the\\nimage which appears in the reconstruction plane will beof the path traveled by the\\n\\n14\\n\\n. .. .. .\\n. . .\\n.\\n\\nI\\n\\nobject during the observation time\\nT. However, if VT < d,then\\nT becomes the dominantfunction.\\nThis condition is theusualsituationencounteredintheliterature\\n( r e f s . 1 , . 3 , 4, and 5).\\n\\nLimiting Conditions\\nEquation(37) is validonly i equation(23) is satisfied. It hasbeenshownin\\nf\\nreference 1 that a further condition which must be satisfied in Fraunhofer holography is\\n\\nz\\n\\n1<-\\n\\n100d2\\nh\\n\\n(44)\\n\\nEquation (44) must be satisfied in order to achieve a usable signal-to-noise ratio in\\nthe recorded fringe pattern. From consideration of equations (23) and (44) and of\\nfigure 2\\n\\n,\\n\\nConsideration of equation (45) and figure 2 yields the conditions under which fringes\\nwhich are proportional to the object velocity may be recorded in the hologram.\\n\\nand since\\n\\nVT\\n\\n- R, equation (23) becomes\\n\\nThe limiting condition given by equation (45) is probably of the greatest interest.\\nFrom the inequality v 5 10d/T, the highest velocities measurable appear to be subject\\nt o the fundamental limitations of thepulsewidthandcoherencelength\\nof thelight\\nsource (laser) used. The inequality appears to indicate that no upper limit to measurable velocities exists if T is required to approach zero. However, during the observation time, enough energy must still be supplied to expose the film;\\nthis requirement\\nimplies use of high-power pulsed lasers. Under this condition, the observation time\\nT becomes synonymous with the pulse width\\nof the laser. The coherence length dec r e a s e s as the pulse width decreases, and ultimately, the coherence length of the light\\ns o u r c e is too small to be used for holography.\\n\\n15\\n\\nReasonable expectations of the state of the art in pulsed-laser technology with\\ncontrollable pulse widths would indicate pulse widths of approximately 1 microsecond.\\nThen if, for example, 1-millimeter objects were measured for their velocities, the\\nhighest measurable velocity would be 10 km/sec. Use of objects as l a r g e as 1 millim e t e r would, however, require a special lens arrangement to keep the experiment\\nwithin the confines of the laboratory walls, as indicated by equation (47).\\n\\nApplications\\nThe technique presented in this study could be used fora wide range of velocity\\nmeasurements of particles in the micron range. With a suitable lens arrangement,\\nperhaps larger particles could be measured. Flow studies could be made on fluids\\nseeded with micron-size particles. The technique\\nwould perhaps be most useful in\\nsituations where present measurement techniques fail; for example,\\nin the measurement of dispersion rates of contaminants around a spacecraft.\\n\\nRead-Out Device\\nThe experiment results of this study are given in t e r m s of microdensitometer\\ntraces. However, because equation (37)\\nis descriptive of the fringes recorded on the\\nf i l m , t h e r e is no reason why the resultant hologram cannot be reconstructed to produce\\nthe image of the path traveled by the object during the observation time. Velocity\\nmeasurement is an almost direct measurement because the path length divided by the\\nexposure time yields the velocity. This technique for measuring velocity eliminates\\nthe need to know z1 and X. These two p a r a m e t e r s , in a plane-wave construction and\\nreconstruction, control only the distance from the hologram to the image plane; the\\nimage plane can be located visually by seeking the sharpest focus.\\n\\nEXPERIMENT RESULTS\\nDuring the development of the theory discussed in this report, two questions\\nconcerning the validity of the two assumptions made in the study were raised.\\n1. The Fourier translation theorem is well -hewn and is accepted for displacements which do not vary with time. However, is the theorem valid f o r displacements\\nwhich vary with t i m e ? It was tacitly assumed in the transition from equation (25) to\\nequation (26) and from equation (26) to equation (27) that the theorem was valid.\\n2. Is the film a sufficiently linear recorder to allow the transition from equation (35) to equation (36) and from equation (36) to equation (37)?\\nTo provide the most convincing answer to the validity questions, an experiment\\non a one-dimensional object moving with a constant velocity was designed. The devised experiment was simple for two reasons. First, the experiment was sufficient\\nto resolve the previously discussed questions; second, the experiment provided\\nan\\nunderstanding of the effect of T and V (eqs. (31) and (38)) upon each other.\\n\\n16\\n\\nThe Experiment Arrangement\\nThe experiment arrangement used is shown in figure 3. The equipment used was\\n\\nas follows.\\n1. The light source w a s a continuous-wave helium-neon laser which operated at\\na 6328-angstrom wavelength.\\n2. The object was an opaque wire, approximately\\n109 microns in diameter,\\nwhich moved into the page (fig. 3) with a variable velocity v.\\n\\n3. The object was transported by means of a linear actuator with a lead of\\n\\n0. 1 inch per revolution.\\n4.\\n\\nThe linear actuator was driven by a motor shaft which could be varied from\\n\\na speed of 0 to 5000 rpm.\\n5. A 35-millimeter camera was used in the recording (7-plane. The exposure\\ntime was 1/125 of a second, and the film was type SO-233.\\n6. Theformationdistancez1\\n\\nw a s 94 centimeters.\\n\\nY\\n\\nLaser and\\nauto col I imator\\n\\n=\\nI\\n\\n1\\n\\nPlane\\nwave\\n\\nt\\n\\nn\\nRecording\\n\\nWire, m\\n\\nI_-\\n\\nt\\n\\nvo pagey i v n with p 5 ~\\ne l o cvi t\\ng\\n\\nI\\n-\\n\\n~.\\n\\nz1\\n\\n__I\\n\\nFigure 3. - Experimental arrangement.\\nSeveral experiments were performed with all system parameters, except the\\nobject velocity, kept constant. Each experiment was performed twice, once\\nat maximum laser intensity and once at lower laser intensity. Table I shows the experiments\\nperformed and the controls on each experiment.\\n\\n17\\n\\n~\\n\\n~\\n\\n~\\n\\nTABLE I. - EXPERIMENTS PERFORMED AND CONTROLS\\n\\nI\\n\\n]\\n\\n~~\\n\\nL a s e r Experid7\\nment\\n\\'17\\nintensity\\nmicrons\\nno.\\ncm\\nHigh\\nLow\\n\\nI\\n\\n1\\n\\n~~\\n\\n0.254\\n,254\\n\\n0\\n0\\n\\nQ\\n0\\n\\n0.254\\n.254\\n\\n642\\n642\\n\\n2. 72\\n2. 72\\n\\n2 18\\n2 18\\n\\nVT\\nVT\\n\\n0.254\\n.254\\n\\n9 64\\n9 64\\n\\n4.09\\n4.09\\n\\n327\\n327\\n\\nvr > d\\nVT > d\\n\\nQ\\n0\\n\\nvr < d\\nvr < d\\n\\n~~\\n\\n1\\n\\n1/125\\n1/125\\n\\nI\\n\\nHigh\\nLow\\n\\nsec\\n\\n1/125\\n1/125\\n\\n109\\n\\n\"\\n\\nHigh\\n\\nLinear Linear\\nkctuator actuator Object\\n,\\nlead <, shaft, velocity, microns Remarks\\ncm/sec\\ncm/rev\\nrPm\\n\\n7-7\\n\\nI\\n\\n>d\\n>d\\n\\n~\\n\\n\"\\n\\n1/125\\n1/125\\n~~~\\n\\nComparison of Theory and Experiment\\nFigures 4 to 9 graph the experiment results. A check of experiment measurements versus theoretically predicted measurements of the distance from the center of\\nT o r V, depending on which was dominant (fig. 2 and eqs. (31) and (38)), to the first\\nzero crossing was made for each experiment. A comparison of these measurements\\nis presented in table 11. The measurement intervals on figures 4 to 9 indicate the experimentally determined positions of the first zeros and the centers of each experiment\\nfigure.\\n\\n1\\n\\nI\\n\\nI\\n\\nI\\n\\nI\\n\\nI\\n\\nI\\n\\nI\\n\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\nI\\n\\n1\\n\\n8\\n\\n9\\n\\nI\\n\\n1\\n\\n1\\n\\n1\\n\\n1\\n\\n10 11 1 2 13 1 4 15 16 17 18\\n\\n5 , mm\\n\\nFigure 4 . - Microdensitometer trace of experiment l a .\\n\\n18\\n\\n3\\n\\nrn\\n0\\n\\nI\\n\\nt\\n1\\n\\n0\\n\\n1\\n\\n1\\n2\\n\\n1\\n\\n3\\n\\n1\\n4\\n\\n1\\n5\\n\\n1\\n\\n6\\n\\n1\\n7\\n\\n1\\n\\n8\\n\\n1\\n9\\n\\n1\\n\\n1\\n\\n1\\n\\n1\\n\\n1\\n\\nI\\n\\nI\\n\\nI\\n\\nI\\n\\n10 11 12 1 3 14 15 1 6 17 18\\n\\n5 , tntn\\n\\nFigure 5.\\n\\n-\\n\\nMicrodensitometer trace of experiment l b .\\n\\nn\\n\\nFigure 6.\\n\\n-\\n\\nMicrodensitometer trace of experiment 2a.\\n\\n19\\n\\nJI\\n\\n7 i\\n\\nm\\n0\\n\\nI\\n\\nt\\n1\\n0\\n\\nl\\n1\\n\\nl\\n2\\n\\nl\\n3\\n\\nl\\n4\\n\\nl\\n5\\n\\nl\\n6\\n\\nl\\n7\\n\\nl\\n8\\n\\nl\\n9\\n\\nl\\nl\\n1\\nl\\nl\\n1 0 11 1 2 13 1 4\\n5 , mm\\n\\n1\\nl\\nl\\nl\\n15 16 1 7 18\\n\\nFigure 7 . - Microdensitometer trace of experiment 2b.\\n\\nP\\n\\n7\\n\\nm\\n\\nP\\n\\n0\\n\\nI\\n\\nt\\nI\\n\\n0\\n\\nI\\n\\nI\\n\\n1\\n\\n1\\n\\n1\\n\\n1\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n-\\n\\n1\\n\\n1\\n\\n8\\n\\n9\\n\\n10\\n\\n1\\n\\n1\\n\\n1\\n\\n1\\n\\n1\\n\\n1\\n\\n11 1 2 13 1 4 15 16 17 18\\n\\n5 , rnm\\n\\nFigure 8. - Microdensitometer trace of experiment 3a.\\n\\n20\\n\\n1\\n\\nI\\n\\n0\\n\\n- 1 - I . 1 1\\n1 2 3 4\\n\\nI\\n\\nI\\n\\nI\\n\\n5\\n\\n6\\n\\n7\\n\\nI\\n8\\n\\nI\\n9\\n\\nI\\n\\n10\\n\\nI\\nI\\n1\\nI\\n11 1 2 13 1 4\\n\\nI\\n15\\n\\nI\\n\\nI\\n\\nI\\n\\n1 6 18\\n7\\n\\nFigure 9. - Microdensitometer trace of experiment 3b.\\nTABLE 11. - COMPARISON O F THEORETICAL AND EXPERIMENTAL RESULTS\\n__\\n\\n\"\\n\\nExperiment no. d, microns\\n\\nVT.\\n\\nmicrons\\n\\nftiozse rtorzse r o ,\\nr t f io, t\\nmm\\n\\n109\\n109\\n\\n0\\n0\\n\\n5.45\\n5.45\\n\\n109\\n109\\n\\n218\\n218\\n\\n2.72\\n2. 72\\n\\n109\\n4.09\\n\\n327\\n327\\n\\n1.82\\n1. 82\\n\\nExamination of table I1 shows that error exists in the experiment results. This\\ne r r o r is explained on the basis of the following error sources\\n1. Readings in revolutions per minute are related directly to velocity.\\n\\n2. The linear actuator lead may have been\\ndirectly to velocity.\\n\\nin e r r o r . T h i s e r r o r\\n\\nis related\\n\\n3.\\n\\nLocation of the zeros on the microdensitometer traces was not precise.\\n\\n4.\\n\\nThe mechanical shutter on the camera was possibly inconsistent.\\n21\\n\\nWhen all t h e p o s s i b l e e r r o r s o u r c e s i n the experiment are considered, the only\\nerror source that can affect the physical measurements the diffraction pattern when\\nof\\nthe object is stationary is the location of the zeros on the microdensitometer traces.\\nThe conclusion is that the observed radical changes in the physical dimensionsof the\\ndiffraction patterns are due solely to object motion. It is further concluded that a close\\ncorrelation exists between the observed changes in physical dimensions and the changes\\npredicted by this study. The purpose of this study was to establish the existence of the\\ncorrelation; future studies can, no doubt, refine the technique used in this study.\\n\\nCONCLUSIONS\\nThis study has shown that it is possible to use the in-line Fraunhofer scheme to\\nf o r m a continuous-exposure hologram of an object in motion. The study has also\\ngiven an expression for the recorded fringe pattern. This expression shows the effect\\nof the object motion upon the usually recorded fringes which are proportional to the\\nobject geometry.\\nManned Spacecraft Center\\nNational Aeronautics and Space Administration\\nHouston, Texas,September 12,\\n1969\\n039-00-00-00-72\\n\\nREFERENCES\\n1. DeVelis, J. B. ; andReynolds, G. 0. : TheoryandApplications\\nAddison-WesleyPublishing C o . , 1967.\\n\\n2.\\n\\nof Holography.\\n\\nP a r r e n t , G. B . , Jr. ; andThompson, B. J. : Huygens\\'Principle.Society\\nof\\nPhoto-Optical Instrumentation Engineers, vol.\\n3,Dec.1964and\\nJan. 1965,\\npp.\\n57-59.\\n\\n3. P a r r e n t , G. B., Jr. ; andThompson, B. J. : On theFraunhofer (Far Field)\\nDiffraction Patterns of Opaque and Transparent Objects With Coherent Background.\\nOptica\\nActa,\\nvol.\\n2, Apr. 1964, 183-194.\\npp.\\n4.Stroke,\\nG. W. : An IntroductiontoCoherentOpticsandHolography.Academic\\nP r e s s , 1966.\\nof\\n5. Thompson, B. J. : Diffraction by OpaqueandTransparentParticles.Society\\nPhoto-Optical Instrumentation Engineers, vol.\\n2, Dec.1963and\\nJan. 1964,\\npp.\\n53-56.\\n6. Powell,R. L. ; and Stetson, K. A. : Interferometric Vibration Analysis by WavefrontReconstruction. J. Opt.\\nSOC. Am.,vol.\\n55, Dec.\\n1965, 1593-1598.\\npp.\\n\\n22\\n\\nNASA-Langley, 1969\\n\\n- 14\\n\\ns-220\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKGIrmPNTtK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rake_nltk_var = Rake()\n",
        "\n",
        "rake_nltk_var.extract_keywords_from_text(str(texts[0][1]))\n",
        "keyword_extracted = rake_nltk_var.get_ranked_phrases()[:5]\n",
        "print(keyword_extracted)\n"
      ],
      "metadata": {
        "id": "kMkD_I6PR524",
        "outputId": "ddb1bd66-70e1-4819-d5c1-7103ed244476",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nh .\\\\ nh .\\\\ nc .\\\\ nt .\\\\ nj .\\\\ ne .\\\\ nh .\\\\ nf .\\\\ nn .\\\\ n', 'nm .\\\\ nw .\\\\ nj .\\\\ ne .\\\\ nj .\\\\ nf .\\\\ nj .\\\\ nh .\\\\ ne .\\\\ n', 'nw .\\\\ nd .\\\\ nb .\\\\ nr .\\\\ nj .\\\\ ng .\\\\ ni .\\\\ nr .\\\\ n', \"bellcomm .\\\\ ninc .\\\\ n9 5 5 l \\\\' enfant\", 'niv .\\\\ nv .\\\\ nvi .\\\\ nvii .\\\\ n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization"
      ],
      "metadata": {
        "id": "juFdHsgmo7du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = requests.get(api_root + '/api/citations/19810002806').json()"
      ],
      "metadata": {
        "id": "lZKuTEm4o7Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = str(requests.get(api_root + resp['downloads'][0]['links']['fulltext']).content)"
      ],
      "metadata": {
        "id": "7cGgwOB1pRWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.summarization import summarize"
      ],
      "metadata": {
        "id": "RGVaWQMrpTdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summarize(doc,0.01), sep='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASkI1sALqAvY",
        "outputId": "bd022573-6706-43f9-d46f-7fc96f0e23d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of Report and Period covered\\n\\nTRW Defense and Space Systems Group\\nPower Conversion Electronics Department\\nOne Space Park\\nRedondo Beach, California\\t 90278\\t\\n_\\n12, Sponsoring Ap ncy Nema and Address\\n\\nFinal TECH.\\nJune 1976- Jan. 1980\\n14, Sponsoring Apmcy code\\n\\nNASA Lewis Research Center\\n21000 Brookpark Road\\nC leveland, Ohio\\t 44135\\n\\n15, Supplementary Notes\\n\\nNASA Technical Monitor:\\t\\n\\n18,\\n\\n4\\n\\nJoseph Kolecki\\n\\nAbstract\\nThree basic switchin g regulators:\\t\\n\\nbuck, boost, and buck/boost, employing a Standardized\\n\\nControl Module (SCM) were characterized by a common small signal block diagram in Volume I of\\n\\nthe report, \"Application Handbook for a Standardized Control Module for DC-DC Converters,\"\\nEmploying the unified model, regulator performance such as stability, aud\\'iosusceptibility,\\n\\noutput impedance, and step-load transient were analyzed and key performance indices were\\nexpressed in simple analytical forms,\\t It has been demonstrated that the performance characteristics of all three regulators are shown to enjoy common properties due to the unique SCM_\\n\\ncontrol scheme.\\t This allows simple unified design procedure to be.realized in the present\\nreport (Volume II) for selecting the key SCM control parameters for an arbitrarily given power.stage configuration and parameter values, such that all regulator performance specifications\\n\\ncan be met and optimized concurrently in a sing le; design attempt.\\nIt is the author\\'; intent to make this report\\n\\n(Volume II)\\n\\nbe\\n\\nself -contained.\\t\\n\\nFor user\\'s\\n\\nconvenience, if he (or she)does not with to go through the detailed modeling and performance\\nanalyses as presented in\\n\\nVolume I,\\n\\nall key results and performance indices derived-in Volume I\\n\\nWhich are relevant to SCM design considerations are presented here in Volume II to facilitate\\nfrequent references,\\n\\n18, Distribution Statement\\n\\n17, Kay Words_iSuppested by Author(s)) _\\n\\n-DC-DC Converters\\t\\nPerformance Analysis\\nStandardized Control Module\\nUnclassified - Unlimited\\nAnalog Signal Processor\\nDigital Signal Processor\\nStability Analysis\\nDiscrete Time Domain Anal sis\\n21.\n",
            "xw?1ple- 3 DESIGN\\n\\n114\\t\\n\\nDETERMINATION OF 1%SIhE\\'RANCE FOR a\\'\\n\\n119\\n\\n6.3\\n6.4\\n\\n6.7\\n6.8\\n\\n);\\n\\n\\t\\n\\n{\\n\\n- gUCC.\\t\\nC\\n\\nPage\\n\\nNo!\\n\\n6.3(A) OPEN-LOOP CAIN, THEORY AND ` ME,ASURFMENT, OF THE\\nRUCK/UOOS1 CONVERTER IN Example\\n\\n4\\n\\nDESIGN\\t\\n\\n12\\n\\n6.9(0) OPEN-LOOP PHASE, IMEORY AND MEASUREMENT, OF THE\\nBUCK/BOOST CONVERTER IN Exempla 4 DESIGN\\t\\n\\n123\\n\\nAUDIO-SUSCEPTIBILITY CHARACTERISTIC, THEORY AND\\nExampxa 4 DESIGN \\t\\n\\n124\\n\\n6.10\\t\\n\\nMEASUREMENT, IN\\n\\n6.11\\t\\n\\nOUTPUT IMPEDANCE CRARACTERISTIC 0 TREORY AND\\n\\nRxampxa 4 DESIGN\\t\\nSTEP LOAD TRANSIENT RESPONSE IN Example 4 DESIGN\\t\\n\\nMEASUREMENT, IN\\n6.12\\t\\nE\\n\\nI\\n\\n125\\n126\\n\\n^\\nI\\n\\n1\\n\\nY\\n\\ni\\n\\nLIST Off` TABLES\\n\\nr\\n\\ni>\\t\\n\\nPACE\\nr\\t\\n\\nTABLE 3.1\\n\\nSUMMARY OF TRANSFER FUNCTIONS FOR ALL FUNCTIONAL\\nBLOCKS\\n\\nZS\\n\\nTABLE 3.2\\n\\nPULSE MODULATOR GAIN\\n\\n19\\n\\nTABLE 6.1\\n\\nSUMMARIES\\n\\nTABLE 6.2\\n\\nSUMMARIES OF THE BUCK/BOOST CONVERTER PERFORMANCES\\n(THEORY AND MEASUREMENT)\\n\\ni\\n\\nd\\n\\nOF BUCK REGULATOR PERFORMANCE CHARACTERISTICS\\n\\n104\\n\\n1 27\\n\\nI\\n\\ni\\n\\ni\\n\\n1\\n\\n(vii)\\'\\n\\nr\\n\\n\\t\\n\\nNOTATIONS\\nThe symbols for currents and voltaScs at 0e torq:inals of devices\\n\\nhave subscripts, The uppercase and lowercase zymbols and subscripts are\\nP\\n\\nused to distinguish between instantaneous values, quiescent values, and\\nsmall signal low-frequency averaged values.\\nvI\\t\\n\\nFor example;\\t\\n\\ninput voltagav instantaneous value\\n\\nr\\t\\n\\nv\\t\\n\\nI\\t\\n\\nV +v\\nI\\n\\n}\\nVI : input voltage, do average value\\ni\\nvi\\t\\n\\n`\\t\\n\\ni\\n\\n\\'\\t\\n\\ninput voltage, small signal low-frequency\\naverage term\\n\\nv0 s U\\' p ut voltage, instantaneous value\\nv0\\n\\nV\\n\\n+ v\\n\\nV\\' out)ut voltage, do average term\\nvo : output voltage, small-signal law-frequency\\naverage term.\\nTp : Period Oaf a switching cycle\\nTON : Switch on time\\nTFI: Switch off time in continuous inductor mmf operation\\n\\nTF2: A portion of the switching off time when the inductor mmf\\nhas vanished\\nd\\t\\nD\\t\\n\\nTON\\t\\n\\n_\\n\\nduty cycle ratio d z D+ a\\n\\nT\\n\\nSteady state duty cycle ratio\\nSmall signal, duty cycle variation\\n\\nd i\\t\\n\\nTOFF\\n\\ndt x D \\t\\n\\nd\\n\\nT\\n\\nD\\'\\t\\n\\nSteady state value for d\\'\\n-vii-\\n\\n9\\n\\nV\\n\\nC\\n\\n; Output filter capacitor voltage\\n\\nL ;\\n\\nInductor current of the buck, and boost converter\\n\\nMagnetie.\n",
            "The following performance improvements were observed\\n\\nand verified in rev ent: modeling and analysis efforts as discussed\\n\\n^\\'\\n\\na\\n\\nF\\n\\nt\\n\\n3\\n\\n1\\nk\\n\\nt\\n\\nCQ\\n\\ni\\n\\nt\\n^\\n\\nf\\n1\\n\\nt\\n\\n^\\n\\nt\\n\\nw\\xc2\\xb0\\n\\nUP\\n\\nwo\\t\\n\\n^\\n\\nto\\n\\na.\\n\\nZZ\\n\\n\\'U\\n\\nH; FVVJ\\n\\nT\\n\\nQ\\nIM\\n\\no\\n\\n9\\n\\nt\\n\\nIx\\n\\nN\\n\\nm\\n\\nLO)\\n\\nui\\nf\\n\\n{\\n\\nr-i\\n\\nD\\n\\nui -\\n\\n3\\n\\nzo\\nCL\\n\\nw\\n\\nw\\n\\nFp\\n\\nI_)\\n\\nH I ^.\\n\\nii\\n\\nin detail in Volume 1 of this report, Application Handbook for a\\nStandardized Control Module for DC-DC Converters.\\'\\n(1) High-gain, wide-bandwidth, and precision regulation\\n(2) Superior dynamic performances, such as taudiosusceptibility \\t\\n\\nE\\n\\nand transient response\\n(3) Stabilisation effect by shifting the positive zero oat the\\nright-half 9-plane to the left-half s- plana.\\n(4) A control :adaptive to the output filter parameter variations\\ndue to environmental rhangas, duty cycle modulations, and\\ncapacitive loading.\\nIn the present volume, the.\n",
            "Attention is now\\nbeing focused on development of analysis-based design guidelines for\\nselecting control parameters In, the ASP in order to achieve the\\nfollowing specified dynamic performances in one non-iterative design\\n\\nattempt:\\nA) frequency domain converter performance chara \\xe2\\x96\\xbacteristics\\n\\xe2\\x80\\xa2 Response of vA to a\\xe2\\x96\\xba sinusoidal, disturbance in v l (audio\\n\\nsusceptibility)\\n\\ni\\n\\nCHAPTER 111\\t\\n\\nj\\t\\n\\nANALYTICAL MODELS AND\\n\\n\\'a\\n\\nPt:1VORMANCC CHARACTERISTICS\\n\\nAs presented in, Volume 1 of this report, tine three basic SCR\\nswitching \\'^,regul.ators, buck, boost\\ncall\\n\\t\\n\\nand\\n\\nbuck/b oost ahown In Fig. la,\\n\\n\"\\'epresented by the common ftequeacy domain block diagram \\t\\n\\nshown i n Fig. 1.2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUN_tlEGqI-p",
        "outputId": "226ca103-b504-4813-bfa6-de19d6753900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 16.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38y3DMzo8YrO",
        "outputId": "4febfccd-d921-48e9-efce-e2c61a6177db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 12.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "G8QZ_AofqNc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "6FLtzmwX7yAd",
        "outputId": "5ce937fd-ee91-4ebd-f533-eff7cf5ce803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d37c78436823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't5-small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't5-small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T5Tokenizer.from_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3bJKDuQ8M8K",
        "outputId": "46bd6dbf-f86c-4ef8-c354-c921b52f9d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.utils.dummy_sentencepiece_objects.T5Tokenizer"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3v-DNy_E5E8L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}